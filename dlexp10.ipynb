{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0OX1SlZFulTjyjvnl81wt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SuryaPrakashBolloju/4285/blob/main/dlexp10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5L_gtEHu7EUZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense, Embedding\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "\n",
        "# Load IMDB dataset with only the 5000 most frequent words\n",
        "vocab_size = 5000\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
        "\n",
        "# Print sample data\n",
        "print(\"First review (as token IDs):\", x_train[0])\n",
        "\n",
        "# Reverse word index (shifted by 3 due to reserved indices)\n",
        "word_index = imdb.get_word_index()\n",
        "word_index = {i + 3: word for word, i in word_index.items()}\n",
        "word_index[0], word_index[1], word_index[2] = \"<PAD>\", \"<START>\", \"<UNK>\"\n",
        "\n",
        "# Print reconstructed first review\n",
        "print(\"First review (as words):\", \" \".join([word_index.get(i, \"<UNK>\") for i in x_train[0]]))\n",
        "\n",
        "# Find min & max review lengths\n",
        "max_len = max(len(x) for x in x_train + x_test)\n",
        "min_len = min(len(x) for x in x_train + x_test)\n",
        "print(f\"Max review length: {max_len}, Min review length: {min_len}\")\n",
        "\n",
        "# Pad sequences to a fixed length (400 words)\n",
        "max_words = 400\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=max_words)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=max_words)\n",
        "\n",
        "# Create validation set (20% of training data)\n",
        "val_size = int(0.2 * len(x_train))\n",
        "x_valid, y_valid = x_train[:val_size], y_train[:val_size]\n",
        "x_train_, y_train_ = x_train[val_size:], y_train[val_size:]\n",
        "\n",
        "# Embedding size\n",
        "embd_len = 32\n",
        "\n",
        "# Build Simple RNN Model\n",
        "RNN_model = Sequential(name=\"Simple_RNN\")\n",
        "RNN_model.add(Embedding(vocab_size, embd_len, input_length=max_words))\n",
        "RNN_model.add(SimpleRNN(128, activation='tanh'))\n",
        "RNN_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Model summary\n",
        "print(RNN_model.summary())\n",
        "\n",
        "# Compile model\n",
        "RNN_model.compile(loss=\"binary_crossentropy\",\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "history = RNN_model.fit(x_train_, y_train_,\n",
        "                         batch_size=64,\n",
        "                         epochs=5,\n",
        "                         verbose=1,\n",
        "                         validation_data=(x_valid, y_valid))\n",
        "\n",
        "# Evaluate on test data\n",
        "test_loss, test_acc = RNN_model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# Plot accuracy over epochs\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n"
      ]
    }
  ]
}